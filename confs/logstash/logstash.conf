input {
  file {
    path => "/var/log/pss/*.log"
    type => "log4net-file"
    start_position => "beginning"
  }
}

input {
  rabbitmq {
    exchange => "logger-exchange"
    host  => "127.0.0.1"
    user => "cduhard"
    password => "gotsuper"
    codec => "json"
    type => "rabbitmq"
  }
}

filter {
  if [type] == "rabbitmq" {
    date {
      match => [ "date" ,  "YYYY-MM-dd HH:mm:ss,SSS"]
    }
    mutate {
      add_field => [ "received_at", "%{@timestamp}" ]
      add_field => [ "tracelevel", "" ]
      remove_field => ["date"]
      convert => {
        "thread" => "integer"
      }
    }
  }
}

filter {
  if [type] == "log4net-file" {
    grok {
      remove_field => message
      match => { message => "(?m)%{TIMESTAMP_ISO8601:sourceTimestamp} \[%{NUMBER:thread}\] %{LOGLEVEL:level} +- TraceLevel%{INT:tracelevel}%{GREEDYDATA:tempMessage}"}
      match => { message => "(?m)%{TIMESTAMP_ISO8601:sourceTimestamp} \[%{NUMBER:thread}\] %{LOGLEVEL:level} +- %{GREEDYDATA:tempMessage}" }
      add_field => [ "received_at", "%{@timestamp}" ]
    }
    date {
      match => [ "sourceTimestamp" ,  "YYYY-MM-dd HH:mm:ss,SSS"]
    }
    if !("_grokparsefailure" in [tags]) {
      mutate {
        replace => [ "message" , "%{tempMessage}" ]
      }
    }
    mutate {
      remove_field => [ "tempMessage" ]
      remove_field => [ "sourceTimestamp"]
      convert => {
        "thread" => "integer"
      }
    }
  }
}

output {
  elasticsearch {
    index_type => "log4net"
    host => "127.0.0.1"
    cluster => "vagrant_elasticsearch"
    protocol => "http"
  }
}
